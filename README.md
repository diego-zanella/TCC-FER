# TCC: Advanced Framework for Facial Emotion Recognition

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg)

This repository contains a robust and modular framework for training, evaluating, and comparing deep learning models for Facial Emotion Recognition (FER). The architecture is designed for experimentation, allowing for easy integration of new datasets and models, and provides powerful features like cross-dataset evaluation, ensemble methods, and comprehensive error analysis.

## âœ¨ Key Features

### ğŸ¯ Training Strategies
- **Individual Training:** Train separate models for each dataset
- **Merged Training:** Train models on combined datasets
- **Hybrid Mode:** Execute both strategies and compare results

### ğŸ“Š Multi-Dataset Support
- Currently supports **FER2013**, **RAF-DB**, and **ExpW**
- Easy integration of new datasets via `data_loader.py`
- Automatic data balancing with Random Oversampling

### ğŸ§  Multiple Model Architectures
- Pre-configured for **DenseNet121**, **ResNet50**, and **EfficientNet-B0**
- Uses `timm` and `torchvision` for pre-trained weights
- Simple configuration to add new architectures

### ğŸš€ Intelligent Training Pipeline
- **Pre-trained Model Detection:** Automatically skips training if weights exist
- **Early Stopping:** Prevents overfitting and saves training time
- **Automatic Memory Management:** GPU cache clearing and garbage collection
- **Batch Size Optimization:** Per-model configuration for optimal GPU usage

### ğŸ“ˆ Advanced Evaluation
- **Test-Time Augmentation (TTA):** Improves prediction accuracy
- **Cross-Dataset Evaluation:** Tests generalization across different domains
- **Ensemble Methods:** Combines multiple models (soft/hard voting)
- **Normalized Confusion Matrices:** Shows proportions (0-1) for easy comparison

### ğŸ” Comprehensive Error Analysis
- **Per-Class Error Rates:** Visual breakdown with color coding
- **Top Confused Pairs:** Identifies critical misclassifications
- **Error Distribution Matrix:** Heatmap of confusion patterns
- **Statistical Summary:** Best/worst classes and critical confusions

### ğŸ“ Organized Output Structure
- **Automatic PDF Generation:** High-quality plots ready for academic papers
- **Structured Directories:** Separate folders for each output type
- **CSV Export:** Results table for easy integration with LaTeX/Excel
- **Timestamped Logs:** Detailed execution history

## ğŸ—‚ï¸ Project Structure

```
.
â”œâ”€â”€ main.py                 # Main execution script - unified pipeline
â”œâ”€â”€ config.py               # Central configuration (models, datasets, hyperparameters)
â”œâ”€â”€ data_loader.py          # Dataset loading, splitting, and balancing
â”œâ”€â”€ model_utils.py          # Model creation and ensemble logic
â”œâ”€â”€ training.py             # Training and evaluation loops
â”œâ”€â”€ utils.py                # Plotting, logging, and error analysis utilities
â”‚
â”œâ”€â”€ fer2013/                # FER2013 dataset directory
â”œâ”€â”€ rafdb/                  # RAF-DB dataset directory
â”œâ”€â”€ expw/                   # Expression in-the-Wild dataset directory
â”‚
â””â”€â”€ saidas/                 # Output directory (auto-generated)
    â”œâ”€â”€ execution_log_*.txt
    â”œâ”€â”€ comprehensive_results.csv
    â”œâ”€â”€ saved_models/
    â”œâ”€â”€ class_distributions/
    â”œâ”€â”€ confusion_matrices/
    â”‚   â””â”€â”€ TTA/
    â”œâ”€â”€ error_analysis/
    â”œâ”€â”€ cross_dataset/
    â””â”€â”€ ensemble_results/
```

## ğŸ“¦ Setup and Installation

### 1. Clone the Repository

```bash
git https://github.com/MatheusVMariussi/TCC-FER.git
cd TCC-FER
```

### 2. Install Dependencies

Create a `requirements.txt` file with the following content:

```txt
torch
torchvision
pandas
scikit-learn
matplotlib
seaborn
Pillow
timm
imbalanced-learn
numpy
```

Then install:

```bash
pip install -r requirements.txt
```

### 3. Dataset Structure

This framework expects the following directory structure:

#### **FER2013:**
```
./fer2013/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ angry/
â”‚   â”œâ”€â”€ disgust/
â”‚   â”œâ”€â”€ fear/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ sad/
â”‚   â”œâ”€â”€ surprise/
â”‚   â””â”€â”€ neutral/
â””â”€â”€ test/
    â”œâ”€â”€ angry/
    â””â”€â”€ ...
```

#### **RAF-DB:**
```
./rafdb/DATASET/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ 1/  (surprise)
â”‚   â”œâ”€â”€ 2/  (fear)
â”‚   â”œâ”€â”€ 3/  (disgust)
â”‚   â”œâ”€â”€ 4/  (happy)
â”‚   â”œâ”€â”€ 5/  (sad)
â”‚   â”œâ”€â”€ 6/  (angry)
â”‚   â””â”€â”€ 7/  (neutral)
â””â”€â”€ test/
    â””â”€â”€ ...
```

#### **Expression in-the-Wild (ExpW):**
```
./expw/Expw-F/
â”œâ”€â”€ angry/
â”œâ”€â”€ disgust/
â”œâ”€â”€ fear/
â”œâ”€â”€ happy/
â”œâ”€â”€ sad/
â”œâ”€â”€ surprise/
â””â”€â”€ neutral/
```

## ğŸš€ How to Use

### 1. Configure Your Experiment

Open `config.py` and customize your settings:

#### **Choose Training Strategy:**
```python
# Train only individual models (one per dataset)
TRAINING_STRATEGY = 'individual'

# Train only merged model (all datasets combined)
TRAINING_STRATEGY = 'merged'

# Train both and compare (RECOMMENDED)
TRAINING_STRATEGY = 'both'
```

#### **Select Active Datasets:**
```python
ACTIVE_DATASETS = {
    'RAF-DB': 'load_rafdb',
    'ExpW': 'load_expw',
    'FER2013': 'load_fer2013',  # Comment out to deactivate
}
```

#### **Configure Models:**
```python
MODEL_CONFIG = {
    'densenet121': {'batch_size': 96},
    'resnet50': {'batch_size': 128},
    'efficientnet_b0': {'batch_size': 128},
    # Add more models here
}
```

#### **Output Settings:**
```python
PLOT_FORMAT = 'pdf'      # 'pdf' or 'png'
NORMALIZE_CM = True      # Normalize confusion matrices (0-1)
```

#### **Hyperparameters:**
```python
EPOCHS = 100             # Max epochs (early stopping may stop sooner)
LEARNING_RATE = 0.001
PATIENCE = 5             # Early stopping patience
```

### 2. Run the Pipeline

```bash
python main.py
```

The script will automatically:
- âœ… Load and balance datasets
- âœ… Train models (or load existing weights)
- âœ… Evaluate with and without TTA
- âœ… Generate confusion matrices
- âœ… Perform error analysis
- âœ… Cross-dataset evaluation
- âœ… Ensemble evaluation
- âœ… Export comprehensive results table

### 3. Review the Outputs

All results are saved to `saidas/` with the following structure:

```
saidas/
â”œâ”€â”€ execution_log_20241025_143022.txt       # Detailed log
â”œâ”€â”€ comprehensive_results.csv               # Main results table
â”‚
â”œâ”€â”€ saved_models/                           # Trained model weights
â”‚   â”œâ”€â”€ RAF-DB_densenet121.pth
â”‚   â”œâ”€â”€ merged_densenet121.pth
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ class_distributions/                    # Dataset distributions
â”‚   â”œâ”€â”€ RAF-DB_dist_original.pdf
â”‚   â”œâ”€â”€ RAF-DB_dist_balanced.pdf
â”‚   â””â”€â”€ merged_train_distribution.pdf
â”‚
â”œâ”€â”€ confusion_matrices/
â”‚   â””â”€â”€ TTA/                                # All TTA confusion matrices
â”‚       â”œâ”€â”€ RAF-DB_densenet121_cm_TTA.pdf
â”‚       â”œâ”€â”€ merged_densenet121_RAF-DB_cm_TTA.pdf
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ error_analysis/                         # Detailed error analysis
â”‚   â”œâ”€â”€ RAF-DB_densenet121_error_analysis.pdf
â”‚   â”œâ”€â”€ merged_densenet121_RAF-DB_error_analysis.pdf
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ cross_dataset/                          # Generalization tests
â”‚   â”œâ”€â”€ cross_dataset_individual.pdf
â”‚   â””â”€â”€ cross_dataset_merged.pdf
â”‚
â””â”€â”€ ensemble_results/                       # Ensemble evaluations
    â”œâ”€â”€ ensemble_individual_RAF-DB_cm.pdf
    â”œâ”€â”€ ensemble_individual_RAF-DB_error.pdf
    â”œâ”€â”€ ensemble_merged_RAF-DB_cm.pdf
    â””â”€â”€ ensemble_merged_RAF-DB_error.pdf
```

## ğŸ“Š Understanding the Outputs

### **Confusion Matrix (Normalized)**
Shows prediction accuracy as proportions (0-1):
- **Diagonal:** Correct predictions (higher = better)
- **Off-diagonal:** Confusions between classes
- Values sum to 1.0 per row (true label)

### **Error Analysis Plot**
Four-panel visualization:
1. **Top:** Per-class error rates (color-coded by severity)
2. **Middle:** Top 10 most confused class pairs
3. **Bottom-Left:** Error distribution heatmap
4. **Bottom-Right:** Statistical summary

### **Cross-Dataset Evaluation**
Heatmap showing model generalization:
- **Rows:** Training dataset
- **Columns:** Test dataset
- **Cells:** Accuracy (darker = better)
- **Blue boxes:** Same dataset (expected high accuracy)

### **Comprehensive Results Table (CSV)**
Complete results in tabular format:
- Section 1: Individual model accuracies
- Section 2: Merged model accuracies
- Section 3: Individual ensemble results
- Section 4: Merged ensemble results

**â­ If this framework helped your research, please consider starring the repository!**